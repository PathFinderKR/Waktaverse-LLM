{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Importing Libraries",
   "id": "52b28e5448565d4"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-09T03:54:54.164375Z",
     "start_time": "2024-06-09T03:54:49.586309Z"
    }
   },
   "source": [
    "# pytorch\n",
    "import torch\n",
    "\n",
    "# huggingface\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Configuration",
   "id": "f0b01c4a1ba77281"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class CONFIG:\n",
    "    device = None\n",
    "    \n",
    "    # Model\n",
    "    base_model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "    model_id = \"Waktaverse-Llama-3-KO-8B-Instruct\"\n",
    "    username = \"PathFinderKR\"\n",
    "    repo_id = f\"{username}/{model_id}\""
   ],
   "id": "1c0243ec756c412c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Device",
   "id": "a878573a8643457f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T03:54:54.233663Z",
     "start_time": "2024-06-09T03:54:54.169351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def configure_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        num_gpu = torch.cuda.device_count()\n",
    "        print(\"> Running on GPU\", end=' | ')\n",
    "        print(\"Num of GPUs: \", num_gpu)\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        print(\"> Running on MPS\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"> Running on CPU\")\n",
    "    return device\n",
    "\n",
    "CONFIG.device = configure_device()"
   ],
   "id": "bd09a320658535ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cuda:0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Merge",
   "id": "c6a8203abf3e30b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T03:55:22.933711Z",
     "start_time": "2024-06-09T03:54:54.241856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(CONFIG.base_model_id)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    CONFIG.base_model_id,\n",
    "    device_map=CONFIG.device,\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True\n",
    ")"
   ],
   "id": "21830c03da1c481",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0a0e2cd3fb7d4b59b0fbc309d42e6a4d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T03:55:27.542324Z",
     "start_time": "2024-06-09T03:55:22.935158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = PeftModel.from_pretrained(base_model, CONFIG.model_id)\n",
    "model = model.merge_and_unload()"
   ],
   "id": "da760abcfbe32fa9",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Upload",
   "id": "7d586f11b9cc3176"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T04:20:48.738960Z",
     "start_time": "2024-06-09T03:55:27.543831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer.push_to_hub(\n",
    "    repo_id=CONFIG.repo_id,\n",
    "    use_temp_dir=False\n",
    ")\n",
    "model.push_to_hub(\n",
    "    repo_id=CONFIG.repo_id,\n",
    "    use_temp_dir=False\n",
    ")"
   ],
   "id": "37edc637f9999a55",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/8.28k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "141a87e157244175913cad8c34c0a160"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "06894100d90c45069dd84d34155c1be4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9f11a34e27314bada01bc97123b58d32"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5f6a94f70bbb4f6c982584b2d074f8df"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6d39b2e551a34475842e8f74f1be3538"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1e0c3d24797446f6972c6e0b005f63e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/PathFinderKR/Waktaverse-Llama-3-KO-8B-Instruct/commit/5bfbd92b09c175942efd041a55498d2705c47f50', commit_message='Upload LlamaForCausalLM', commit_description='', oid='5bfbd92b09c175942efd041a55498d2705c47f50', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
